---
title: "Le projet R forces"
author:
  - "Méziane Cherif"
  - "Olivier Cailloux"
output: pdf_document
header-includes:
  - \usepackage{newunicodechar}
  - \newunicodechar{μ}{\mu}
  - \newunicodechar{σ}{\sigma}
  - \newunicodechar{∈}{\in}
  - \newunicodechar{≈}{\approx}
---

# Contexte
Commission d’enquête de l’AN
la situation, les missions et les moyens des forces de sécurité
22 mai au 28 juin 2019
agents de la police nationale et des polices municipales, aux militaires de la gendarmerie nationale et aux réservistes

"les éléments des réponses permettant d’identifier le répondant (coordonnées ou risque de ré-identification) ainsi que les réponses comprenant des imputations personnelles ou des insultes ont été supprimés."

https://data.assemblee-nationale.fr/autres/consultations-citoyennes/moyens-des-forces-de-securite

Nous utilisons également les « Principaux indicateurs sur les revenus et la pauvreté aux niveaux national et local en 2019 » du dispositif Fichier localisé social et fiscal (Filosofi) publié par l’INSEE (présentation [ici](https://www.insee.fr/fr/statistiques/6436484), téléchargement [ici](https://www.insee.fr/fr/statistiques/6036902)). Des données plus récentes [existent](https://www.insee.fr/fr/statistiques/7752770) mais nous utilisons les données reflétant la réalité au moment des réponses des forces de sécurité.

# Mise en place
Chargeons quelques packages utiles.
```{r, message=FALSE}
library(conflicted)
conflicts_prefer(dplyr::filter)
library(tidyverse)
library(truncnorm)
```

Téléchargeons les réponses des forces de sécurité, ou vérifions leur conformité si elles sont déjà présentes à l’aide du hash MD5 indiqué sur le site sus-mentionné.
```{r}
answers_url <- paste0(
  "https://data.assemblee-nationale.fr/",
  "static/openData/repository/CONSULTATIONS_CITOYENNES/",
  "MOYENS_DES_FORCES_DE_SECURITE/Moyens-des-forces-de-securite.csv"
)
md5_expected <- "261b4244cc2e9ffcd54ff9a6bec0a0ac"
if (file.exists("Réponses original.csv")) {
  md5_observed <- tools::md5sum("Réponses original.csv")
} else {
  md5_observed <- 0L
}
if (md5_observed != md5_expected) {
  downloaded_return <- download.file(answers_url, "Réponses original.csv", mode = "wb")
  stopifnot(identical(downloaded_return, 0L))
}
md5_observed <- tools::md5sum("Réponses original.csv")
stopifnot(md5_observed == md5_expected)
```
Convertissons en UTF8.
```{r}
input_original <- readLines("Réponses original.csv")
input_converted <- iconv(input_original, from = "WINDOWS-1252", to = "UTF8")
writeLines(input_converted, "Réponses.csv")
```

Téléchargeons de même les données sur les revenus et la pauvreté.
```{r}
zip_file_name <- "base-cc-filosofi-2019_CSV.zip"
filosofi_url <- paste0("https://www.insee.fr/fr/statistiques/fichier/6036902/", zip_file_name)
if (!file.exists(zip_file_name)) {
  downloaded_return <- download.file(filosofi_url, zip_file_name, mode = "wb")
  stopifnot(identical(downloaded_return, 0L))
}

to_extract <- c("cc_filosofi_2019_DEP.csv", "meta_cc_filosofi_2019_DEP.csv")
if (!all(file.exists(to_extract))) {
  unzip(zip_file_name, files = to_extract)
}
```

# Lecture des données
## Réponses
Lisons les réponses des forces de sécurité.
```{r}
answers <- read_delim("Réponses.csv",
  delim = ";", locale = locale(decimal_mark = ","),
  show_col_types = FALSE, name_repair = "minimal"
)
col_renaming <- read_csv("Colonnes.csv", show_col_types = FALSE)
stopifnot(all.equal(colnames(answers), col_renaming[["Nom original"]]))
colnames(answers) <- col_renaming[["Nouveau nom"]]
answers
```

Vérifions que les décimales sont lues correctement et que nous disposons du nombre de contributions annoncé sur le site ministériel.
```{r}
stopifnot(answers |> filter(rep == 9) |> pull(train_days_2017) == 2.5)
stopifnot(nrow(answers) == 13735)
```

## Revenus et pauvreté
Lisons maintenant les données économiques.
```{r}
revenues_poverty <- read_delim("cc_filosofi_2019_DEP.csv",
  delim = ";", locale = locale(decimal_mark = ","),
  show_col_types = FALSE
)
revenues_poverty
```

Vérifions que le revenu médian et le taux de pauvreté de l’Ain sont ceux indiqués [sur le site](https://www.insee.fr/fr/statistiques/6436484?sommaire=6036904#tableau-figure1_radio1).
```{r}
ain <- revenues_poverty |> filter(CODGEO == "01")
stopifnot(ain |> pull(MED19) == 23490)
stopifnot(ain |> pull(TP6019) == 10.7)
```

# Traitement des données
Extrayons le premier mot de la colonne `dept` pour obtenir le code de département (on vérifie avec une réponse donnée que la conversion a fonctionné).
Notons que les départements corses ne s’encodent pas comme des nombres, donc ce code doit être de type chaine de caractères.

Transformons également l’âge donné en nombre entier.

```{r}
stopifnot(answers |> filter(rep == 3) |> pull(dept) == "08 - ARDENNES")
answers <- mutate(answers, dept_nb = str_extract(dept, "^[0-9AB]+"), .after = dept)
stopifnot(answers |> filter(rep == 3) |> pull(dept_nb) == "08")

answers <- answers |>
  filter(!is.na(agemaj)) |>
  filter(agemaj != "Autre")
stopifnot(all(str_detect(answers$agemaj, "^[0-9]+ ans$")))
answers <- mutate(answers, agemaj = as.integer(str_extract(agemaj, "^[0-9]+")))
```

# Croisement des données
Nous pouvons maintenant joindre les données économiques aux réponses des forces de sécurité.
```{r}
data <- left_join(answers, revenues_poverty, by = c("dept_nb" = "CODGEO"))
data
write_csv(data, "Données fusionnées.csv", na = "")
```

# Idées (brouillon)
Nous pourrions analyser le lien entre la pauvreté du lieu d’exercice et l’âge souhaité des mineurs (surtout pauvreté des plus jeunes) ; le manque d’effectif ; le temps de formation ; le nombre de jours supplémentaires impayés et le manque d’effectif ; l’appréciation de la mobilité ; la volonté d’un cadre plus sûr ; la forfaitisation de sanctions…

# Sélection
Considérons le taux de pauvreté dans leur département et l’âge souhaité pour traitement comme un majeur. On ne retient en outre que les enregistrements où ces variables sont toutes renseignées.

```{r}
subset <- data |>
  select("you", "TP6019", "agemaj") |>
  drop_na()
```

# Comparaison de sous-groupes
Les nombres de réponses par types de répondants diffèrent beaucoup. Considérons les deux types de répondants avec le plus de réponses.
```{r}
subset |> ggplot(aes(x = you)) +
  geom_bar() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
highest_answers_type <- subset |>
  select("you") |>
  group_by(you) |>
  count() |>
  ungroup() |>
  slice_max(n, n = 2) |>
  pull(you)
highest_answers_type
indicators_by_type <- subset |>
  filter(you %in% highest_answers_type) |>
  select(you, agemaj) |>
  group_by(you) |>
  summarise(mu = mean(agemaj), "s’" = sd(agemaj), n = n())
indicators_by_type
```
Soit $X^{(1)}$ la variable aléatoire représentant l’âge souhaité pour traitement comme un majeur pour le premier type de répondant et $X^{(2)}$ pour le second type de répondant. 
Définissons $\mu_j$ et $\sigma_j$ les moyennes et écart-types de $X^{(j)}$ respectivement ($j \in \{1, 2\}$). 
Notons $X^{(j)}_i$ les observations correspondantes ($j \in \{1, 2\}$, $i \in \{1, \ldots, n_j\}$). On suppose les $X^{(j)}_i$ indépendantes et identiquement distribuées selon $X^{(j)}$.

Avec l’approximation normale (largement valable vu le nombre de réponses), on a $X^{(j)} \approx \mathcal{N}(μ_j, σ_j^2)$ donc $\overline{X^{(j)}} = \frac{1}{n_j} \sum_{i=1}^{n_j} X^{(j)}_i \approx \mathcal{N}(μ_j, \frac{σ_j^2}{n_j})$ et $\overline{X^{(1)}} - \overline{X^{(2)}} \approx \mathcal{N}(μ_1 - μ_2, \frac{σ_1^2}{n_1} + \frac{σ_2^2}{n_2})$.

Définissons notre hypothèse nulle $H_0$ (que nous tentons de réfuter) comme l’égalité des moyennes : $μ_1 = μ_2$.
Sous $H_0$, $\frac{\overline{X^{(1)}} - \overline{X^{(2)}}}{\sqrt{\frac{σ_1^2}{n_1} + \frac{σ_2^2}{n_2}}} \approx \mathcal{N}(0, 1)$. Avec le Théorème de Slutsky et de continuité, en notant $S'^{(j)^2}$ la variance empirique corrigée des observations $X^{(j)}_i$ et en définissant $Z = \frac{\overline{X^{(1)}} - \overline{X^{(2)}}}{\sqrt{\frac{S'^{(1)^2}}{n_1} + \frac{S'^{(2)^2}}{n_2}}}$, on obtient $Z \approx \mathcal{N}(0, 1)$.
Notons $W$ la région critique et $\overline{W}$ son complémentaire.

```{r, echo=FALSE}
rpes <- c(0.05, 0.1)
rpe1 <- 0.05
rpe2 <- 0.1
prints <- paste0("Avec un risque de première espèce à ", rpes * 100, " %, on a $P(Z ∈ W) = ", rpes, " pour \\overline{W} ≈ [", qnorm(rpes / 2) |> round(2), ", ", qnorm(1 - rpes / 2) |> round(2), "]$.")
```
- `r prints[1]`
- `r prints[2]`

```{r}
z <- (indicators_by_type$mu[1] - indicators_by_type$mu[2]) / sqrt(indicators_by_type[["s’"]][1]^2 / indicators_by_type$n[1] + indicators_by_type[["s’"]][2]^2 / indicators_by_type$n[2])
```

Nous observons $z = `r z |> round(2)`$ et rejettons donc allègrement $H_0$ : les deux moyennes semblent différentes (à un degré de confiance très élevé, p-value de `r (2 * pnorm(-abs(z))) |> format(digits = 2)`).

Voyons ce qu’en pense le test de Welsh de R.
```{r}
series1 <- subset |>
  filter(you == highest_answers_type[1]) |>
  pull(agemaj)
series2 <- subset |>
  filter(you == highest_answers_type[2]) |>
  pull(agemaj)
t.test(x = series1, y = series2, var.equal = FALSE)
```
Ceci confirme nos résultats (bien que le test de Welch n’utilise pas la même distribution approchée que notre approximation par gaussienne comme vu en cours, la différence est extrêmement faible, vu le nombre de nos observations, d’où le fait que la p-value obtenue par R soit du même ordre que la nôtre).

Notons que nous n’avons pas testé l’égalité des variances, nous avons simplement évité de supposer leur égalité, ce qui est plus robuste, ne requiert pas un tel test ([controversé](https://stats.stackexchange.com/a/289455/) dans la littérature), et ne change pas le résultat étant donné que la puissance de notre test est déjà très largement suffisante pour rejeter l’hypothèse nulle.

Nous concluons que les répondants de la police nationale et ceux de la gendarmerie nationale ne semblent pas avoir le même âge souhaité pour traitement comme un majeur. La différence est statistiquement très significative, mais il faut noter que la signification pratique de cette différence est très faible, vu la très faible différence observée (en fait elle est statistiquement significative uniquement grâce à notre très grand nombre d’observations).

# Lien entre le taux de pauvreté et l’âge souhaité
Voyons si le taux de pauvreté dans le département est indépendant de l’âge souhaité pour traitement comme un majeur.

Coupons d’abord les deux séries d’observations en classes d’effectifs proches.
```{r}
povs <- subset |> pull(TP6019)
subset |> ggplot(aes(x = povs)) +
  geom_histogram(binwidth = 1)
subset |> ggplot(aes(x = agemaj)) +
  geom_histogram(binwidth = 1)
povs_bins <- cut_number(povs, n = 10)
subset |> ggplot(aes(x = povs_bins)) +
  geom_bar() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
ages <- subset |> pull(agemaj)
ages_bins <- cut_number(ages, n = 4)
subset |> ggplot(aes(x = ages_bins)) +
  geom_bar() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

Tableau de contingence empirique.
```{r}
table(povs_bins, ages_bins) |> addmargins()
```
Tableau de contingence empirique normalisé par ligne (profils-lignes).
```{r}
table(povs_bins, ages_bins) |>
  prop.table(margin = 1) |>
  addmargins() |>
  round(2)
```

Les fréquences théoriques requièrent une hypothèse de distribution. 
Nous supposons des distributions normales tronquées.
Vu les plots ci-dessus, l’approximation uniforme serait très mauvaise, et l’approximation normale semble inadéquate car les variables sont bornées. Pour la variable pauvreté par exemple, la distribution normale avec les paramètres observés (moyenne `r mean(povs) |> round(2)`, écart-type `r sd(povs) |> round(2)`) aurait une valeur importante en zéro (`r pnorm(0, mean(povs), sd(povs)) |> round(4)`).

Tableau de contingence théorique sous l’hypothèse d’indépendance.
```{r}
# povs_distr <- function(q1, q2) pnorm(q2, mean(povs), sd(povs)) - pnorm(q1, mean(povs), sd(povs))
povs_distr <- function(q1, q2) ptruncnorm(c(q1, q2), mean(povs), sd(povs), a = min(povs), b = max(povs)) |> diff()
stopifnot(povs_distr(-Inf, 0) == 0)
# ages_distr <- function(q1, q2) pnorm(q2, mean(ages), sd(ages)) - pnorm(q1, mean(ages), sd(ages))
ages_distr <- function(q1, q2) ptruncnorm(c(q1, q2), mean(ages), sd(ages), a = min(ages), b = max(ages)) |> diff()
# Très inélégant, mais pas trouvé mieux en restant dans le raisonnablement simple. Merci à https://stackoverflow.com/a/40665505/.
povs_endpoints <- unique(as.numeric(unlist(
  strsplit(gsub("[][(]", "", levels(povs_bins)), ",")
)))
# povs_endpoints[1] <- -Inf
# povs_endpoints[length(povs_endpoints)] <- Inf
ages_endpoints <- unique(as.numeric(unlist(
  strsplit(gsub("[][(]", "", levels(ages_bins)), ",")
)))
povs_probs <- sapply(1:(length(povs_endpoints) - 1), function(i) povs_distr(povs_endpoints[i], povs_endpoints[i + 1]))
# povs_probs
stopifnot(sum(povs_probs) == 1)
ages_probs <- sapply(1:(length(ages_endpoints) - 1), function(i) ages_distr(ages_endpoints[i], ages_endpoints[i + 1]))
stopifnot(sum(ages_probs) == 1)
expected <- outer(povs_probs, ages_probs)
# expected |> addmargins()
ct <- chisq.test(table(povs_bins, ages_bins), p = expected)
pchisq(unname(ct$statistic), df = ct$parameter - 8, lower.tail = FALSE)
```

La probabilité qu’une $χ^2$ à `r ct$parameter - 8` degrés de liberté soit aussi extrême que celle observée est de `r pchisq(unname(ct$statistic), df = ct$parameter - 8, lower.tail = FALSE) |> format(digits = 2)`, on peut donc confortablement rejeter l’hypothèse d’indépendance entre le taux de pauvreté et l’âge souhaité pour traitement comme un majeur. Ceci implique également, a fortiori, le rejet de l’hypothèse aux seuils de 10 % et 5 %.

# Annexe
```{r}
# show relationship with age
subset |> ggplot(aes(x = povs, y = agemaj)) +
  geom_point() +
  geom_smooth(method = "lm")
```
